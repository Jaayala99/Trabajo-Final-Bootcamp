{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primero, cargamos un conjunto de datos que contiene preguntas y respuestas sobre ejercicios físicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el conjunto de datos\n",
    "data = load_dataset('HazSylvia/Fitness_Unformatted')\n",
    "\n",
    "#Convertir los datos a un dataset de Hugging Face\n",
    "dataset = Dataset.from_dict({\n",
    "    \"question\": [item[\"Human\"] for item in data[\"train\"]],\n",
    "    \"answer\": [item[\"Assistant\"] for item in data[\"train\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocesamos los datos para que estén en un formato adecuado para el entrenamiento del modelo GPT-2. Esto implica la tokenización de las preguntas y respuestas y la configuración de las etiquetas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef6acf930434cd3982a26d6512a1d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cargar el modelo y el tokenizador\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 no tiene un token de padding por defecto\n",
    "\n",
    "#Preprocesar los datos\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f\"Question: {question} Answer: {answer}\" for question, answer in zip(examples[\"question\"], examples[\"answer\"])]\n",
    "    model_inputs = tokenizer(inputs, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    labels = model_inputs[\"input_ids\"].clone()\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=[\"question\", \"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuramos los argumentos de entrenamiento y utilizamos un `Trainer` para entrenar el modelo GPT-2 con los datos preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar los argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-question-answering\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "#Usar DataCollator para el padding dinámico\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # No usamos el enmascarado para modelado de lenguaje\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenar el modelo\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez finalizado el entrenamiento, guardamos el modelo y el tokenizador para su uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el modelo entrenado y el tokenizador\n",
    "model.save_pretrained(\"./gpt2-question-answering\")\n",
    "tokenizer.save_pretrained(\"./gpt2-question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función: generate_response(question, model, tokenizer, max_length=512, max_new_tokens=50)\n",
    "\n",
    "1. Cargar el modelo y el tokenizador entrenados desde la ruta especificada.\n",
    "    - Ruta del modelo: \"./gpt2-question-answering\"\n",
    "    - Cargar el modelo GPT2LMHeadModel desde la ruta especificada.\n",
    "    - Cargar el tokenizador GPT2Tokenizer desde la misma ruta.\n",
    "    - Ajustar el token de padding del tokenizador al token EOS.\n",
    "\n",
    "2. Ajustar el tokenizador para evitar advertencias.\n",
    "    - Establecer el lado de padding del tokenizador como \"left\".\n",
    "\n",
    "3. Generar respuestas \n",
    "    - Preparar el prompt incluyendo la pregunta.\n",
    "    - Tokenizar el prompt y preparar los inputs para el modelo.\n",
    "    - Generar la respuesta utilizando el modelo entrenado.\n",
    "    - Decodificar la respuesta y extraer la parte generada.\n",
    "    - Devolver la respuesta generada.\n",
    "\n",
    "Uso:\n",
    "- Hacer una pregunta al modelo y obtener una respuesta generada.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the best way to gain muscle mass?\n",
      "Answer: gaining muscle is essential for muscle growth and strength endurance it is important to prioritize lean muscle groups and prioritize fat loss when possible Answer that gaining lean mass can be achieved in a variety of forms including strength training cardio and musclebuilding workouts it can also\n"
     ]
    }
   ],
   "source": [
    "#Cargar el modelo y el tokenizador entrenados\n",
    "model_path = \"./gpt2-question-answering\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Ajustar el token de padding\n",
    "\n",
    "#Ajustar el tokenizer para evitar advertencias\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "#Función para generar respuestas\n",
    "def generate_response(question, model, tokenizer, max_length=512, max_new_tokens=50):\n",
    "    # Preparar el prompt\n",
    "    prompt = (\n",
    "        \"You are an expert fitness assistant known for providing clear and concise answers to users' questions. \"\n",
    "        f\"Question: {question}\"\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    \n",
    "    # Generar la respuesta\n",
    "    output = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.eos_token_id  # Asegurar el uso del token de padding correcto\n",
    "    )\n",
    "    \n",
    "    # Decodificar la respuesta\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    # Extraer solo la parte de la respuesta generada\n",
    "    answer = answer.replace(prompt, \"\").strip()\n",
    "    return answer\n",
    "\n",
    "# Ejemplo de uso: Hacer una pregunta al modelo\n",
    "question = \"What is the best way to gain muscle mass?\"\n",
    "response = generate_response(question, model, tokenizer)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
